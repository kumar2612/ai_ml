{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiWHyAlMflCOu4dees9FgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar2612/ai_ml/blob/ai_ml_basics_nov2024/langchain_tutorials/4_Build_an_Extraction_Chain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OKC4HVz2-6k",
        "outputId": "98c934cf-1994-45d0-a7d1-62e2fec3acb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.3.21)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.23-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.2.2)\n",
            "Downloading langchain_core-0.3.23-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.21\n",
            "    Uninstalling langchain-core-0.3.21:\n",
            "      Successfully uninstalled langchain-core-0.3.21\n",
            "Successfully installed langchain-core-0.3.23\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"langchain_tutorials\""
      ],
      "metadata": {
        "id": "DOEmAKoD34j9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    # ^ Doc-string for the entity Person.\n",
        "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
        "    # and it can help to improve extraction results.\n",
        "\n",
        "    # Note that:\n",
        "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
        "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
        "    # Having a good description can help improve extraction results.\n",
        "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
        "    hair_color: Optional[str] = Field(\n",
        "        default=None, description=\"The color of the person's hair if known\"\n",
        "    )\n",
        "    height_in_meters: Optional[str] = Field(\n",
        "        default=None, description=\"Height measured in meters\"\n",
        "    )"
      ],
      "metadata": {
        "id": "FZHcCEsHhjB3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert extraction algorithm. \"\n",
        "            \"Only extract relevant information from the text. \"\n",
        "            \"If you do not know the value of an attribute asked to extract, \"\n",
        "            \"return null for the attribute's value.\",\n",
        "        ),\n",
        "        (\"human\", \"{text}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "gRvyUJ_eiKvA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWmkP-2Pi5xW",
        "outputId": "3543059f-782b-47c6-8bc0-61235369e6e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.3.23)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (2.2.3)\n",
            "Downloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.13.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.13.0 langchain-groq-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")"
      ],
      "metadata": {
        "id": "mFY9B7uti31C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm = llm.with_structured_output(schema = Person)"
      ],
      "metadata": {
        "id": "6NWHT8rjjGGQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Alan Smith is 6 feet tall and has blond hair.\"\n",
        "prompt = prompt_template.invoke({\"text\": text})\n",
        "structured_llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwX8RrKSjL3P",
        "outputId": "5228d0d9-e069-4c3f-9bbd-a4e3b9f25580"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Person(name='Alan Smith', hair_color='blond', height_in_meters='1.8288')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    # ^ Doc-string for the entity Person.\n",
        "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
        "    # and it can help to improve extraction results.\n",
        "\n",
        "    # Note that:\n",
        "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
        "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
        "    # Having a good description can help improve extraction results.\n",
        "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
        "    hair_color: Optional[str] = Field(\n",
        "        default=None, description=\"The color of the person's hair if known\"\n",
        "    )\n",
        "    height_in_meters: Optional[str] = Field(\n",
        "        default=None, description=\"Height measured in meters\"\n",
        "    )\n",
        "\n",
        "\n",
        "class Data(BaseModel):\n",
        "    \"\"\"Extracted data about people.\"\"\"\n",
        "\n",
        "    # Creates a model so that we can extract multiple entities.\n",
        "    people: List[Person]"
      ],
      "metadata": {
        "id": "kWKfcQzmkAUw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exraction with multiple people\n",
        "structured_llm = llm.with_structured_output(schema=Data)\n",
        "text = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\n",
        "prompt = prompt_template.invoke({\"text\": text})\n",
        "structured_llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqBxsvB4kCUX",
        "outputId": "691862e1-9c4b-4a27-ccfa-a02e30b1ffaf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(people=[Person(name='Jeff', hair_color='black', height_in_meters='1.8288'), Person(name='Anna', hair_color='black', height_in_meters=None)])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#guide llm with alternating user and assistant messages\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"2 🦜 2\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"4\"},\n",
        "    {\"role\": \"user\", \"content\": \"2 🦜 3\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"5\"},\n",
        "    {\"role\": \"user\", \"content\": \"3 🦜 4\"},\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzQ-_WX3kQNx",
        "outputId": "585a498b-d74c-4cca-a1e7-57d0a87e4cba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.utils.function_calling import tool_example_to_messages\n",
        "\n",
        "examples = [\n",
        "    (\n",
        "        \"The ocean is vast and blue. It's more than 20,000 feet deep.\",\n",
        "        Data(people=[]),\n",
        "    ),\n",
        "    (\n",
        "        \"Fiona traveled far from France to Spain.\",\n",
        "        Data(people=[Person(name=\"Fiona\", height_in_meters=None, hair_color=None)]),\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "messages = []\n",
        "\n",
        "for txt, tool_call in examples:\n",
        "    if tool_call.people:\n",
        "        # This final message is optional for some providers\n",
        "        ai_response = \"Detected people.\"\n",
        "    else:\n",
        "        ai_response = \"Detected no people.\"\n",
        "    messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvVWT1kFkpJP",
        "outputId": "094fe338-e054-4262-988a-98a985c15418"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-f29d97645946>:23: LangChainBetaWarning: The function `tool_example_to_messages` is in beta. It is actively being worked on, so the API may change.\n",
            "  messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message in messages:\n",
        "    message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b2kF6T8lkAS",
        "outputId": "f889b3e5-0281-4ab3-bb25-4bd6d185ddcd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "The ocean is vast and blue. It's more than 20,000 feet deep.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Data (a6ad813c-2de5-4a69-a470-12acaeab234e)\n",
            " Call ID: a6ad813c-2de5-4a69-a470-12acaeab234e\n",
            "  Args:\n",
            "    people: []\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "You have correctly called this tool.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Detected no people.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Fiona traveled far from France to Spain.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Data (64f4b5de-0090-4e2b-b2ee-b051bd23dd3f)\n",
            " Call ID: 64f4b5de-0090-4e2b-b2ee-b051bd23dd3f\n",
            "  Args:\n",
            "    people: [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "You have correctly called this tool.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Detected people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_no_extraction = {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"The solar system is large, but earth has only 1 moon.\",\n",
        "}\n",
        "\n",
        "structured_llm = llm.with_structured_output(schema=Data)\n",
        "structured_llm.invoke([message_no_extraction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WltrFRal0ph",
        "outputId": "c6dcf473-1f5a-4885-c4b0-18ba48a2e5e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(people=[Person(name='astronomer', hair_color='brown', height_in_meters='1.75')])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm.invoke(messages + [message_no_extraction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWzzXUmGl_Ut",
        "outputId": "5177e328-459c-42af-f73b-78204ddd4a68"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(people=[])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}