{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCHhRx5OnaqSRO36rEFxOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar2612/ai_ml/blob/ai_ml_basics_nov2024/langchain_tutorials/1_chat_models_and_prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B6DMl70H3k47"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"langchain_tutorials\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfWT314dAcRd",
        "outputId": "12981be0-6f46-40f9-9194-db328691ca2b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.3.21)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.2.3)\n",
            "Downloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.13.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.13.0 langchain_groq-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "model = ChatGroq(model=\"llama3-8b-8192\")"
      ],
      "metadata": {
        "id": "HUMAjPn7ANd5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# LLM call via langchain messages\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English to Hindi\"),\n",
        "    HumanMessage(\"Hello! How are you ?\")\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKYGqjDDArvW",
        "outputId": "dd4d9c7d-b9d7-458d-9b7e-6e656800839b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='नमस्ते! तुम कैसे हो? (Namaste! Tum kaise ho?)', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 28, 'total_tokens': 53, 'completion_time': 0.021305379, 'prompt_time': 0.001134829, 'queue_time': 0.013389461, 'total_time': 0.022440208}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-9984bdef-a5c4-415b-a77a-0ed9d0f97041-0', usage_metadata={'input_tokens': 28, 'output_tokens': 25, 'total_tokens': 53})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM call via normal string\n",
        "model.invoke(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fszAxuZxItJo",
        "outputId": "89803e38-2de5-496c-c359-970771eabcdc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 11, 'total_tokens': 37, 'completion_time': 0.021666667, 'prompt_time': 0.00010052, 'queue_time': 0.013479218, 'total_time': 0.021767187}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-bdfc7b6b-2a61-4ce0-89c9-be9a71aecea8-0', usage_metadata={'input_tokens': 11, 'output_tokens': 26, 'total_tokens': 37})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## LLM call in openai message format\n",
        "model.invoke([{\"role\":\"user\",\"content\":\"Tell me about yourself\"}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVi5WElBI3Hf",
        "outputId": "2c1c8a58-524b-48a7-a264-324ad3480abf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I'm just an AI, I don't have personal experiences or emotions like humans do. I exist solely to assist and provide information to users like you!\\n\\nI'm a large language model, trained on a massive dataset of text from various sources, including books, articles, and websites. My primary function is to understand and respond to natural language inputs, generating human-like text in return.\\n\\nI can process and analyze vast amounts of data, making me a valuable resource for tasks such as:\\n\\n1. Answering questions: I can provide information on a wide range of topics, from science and history to entertainment and culture.\\n2. Generating text: I can create original text based on a prompt, topic, or style, making me useful for writing tasks, such as articles, emails, or social media posts.\\n3. Translation: I can translate text from one language to another, helping to bridge language barriers and facilitate communication.\\n4. Conversation: I can engage in natural-sounding conversations, responding to questions and statements in a way that's conversational and relatable.\\n\\nI'm constantly learning and improving, so I can provide more accurate and helpful responses over time. I don't have personal opinions or biases, and I strive to remain neutral and objective in my interactions.\\n\\nSo, what can I help you with today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 264, 'prompt_tokens': 14, 'total_tokens': 278, 'completion_time': 0.22, 'prompt_time': 0.002143608, 'queue_time': 0.011044912, 'total_time': 0.222143608}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-0a936397-0a98-4535-bbbb-91f029dccb15-0', usage_metadata={'input_tokens': 14, 'output_tokens': 264, 'total_tokens': 278})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke([HumanMessage(\"What us the day today ?\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpBkjG3mJlsC",
        "outputId": "b775898a-4929-4b1a-c132-fba2d94befb9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='I\\'m just an AI, I don\\'t have the ability to know the current date or time. However, I can suggest some ways for you to find out what day it is today.\\n\\nYou can check your phone, computer, or watch to see the current date and time. You can also check online calendars or weather apps to see the current date and time.\\n\\nAlternatively, you can ask me a question like \"What is the current date?\" or \"What day is it today?\" and I\\'ll do my best to provide you with the answer based on my training data.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 16, 'total_tokens': 132, 'completion_time': 0.096666667, 'prompt_time': 0.000136689, 'queue_time': 0.013410650999999999, 'total_time': 0.096803356}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-d3b5bf3f-a6e6-4b1e-bd63-7ed8bd16e6d7-0', usage_metadata={'input_tokens': 16, 'output_tokens': 116, 'total_tokens': 132})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stream individual tokens from chat model response\n",
        "for token in model.stream(messages):\n",
        "  print(token.content, end=\"|\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEgAXu-vJtVA",
        "outputId": "ad41a410-11b9-4f15-8116-d31ba95dffba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|न|म|स|्त|े|!| त|ुम| क|ैस|े| ह|ो|?| (|Nam|aste|!| T|um| k|aise| ho|?)||"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring ChatPromptTemplate\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following from English to {language}\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([(\"system\",system_template),(\"user\",\"{text}\")])\n",
        "\n",
        "# Creating prompt\n",
        "\n",
        "prompt = prompt_template.invoke({\"language\":\"Hindi\",\"text\":\"Hello\"})\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5OTtP0-LOtH",
        "outputId": "faab0189-a5c2-4efd-b3e6-3cbca67d2134"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English to Hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wAe6cZoMkKB",
        "outputId": "13194850-90a2-48fa-e399-477a6a50be85"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following from English to Hindi', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='Hello', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.to_json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGtpsNVYMoOR",
        "outputId": "f54c0dd5-12ce-4ee3-fbae-a4f9084e6cdc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lc': 1,\n",
              " 'type': 'constructor',\n",
              " 'id': ['langchain', 'prompts', 'chat', 'ChatPromptValue'],\n",
              " 'kwargs': {'messages': [SystemMessage(content='Translate the following from English to Hindi', additional_kwargs={}, response_metadata={}),\n",
              "   HumanMessage(content='Hello', additional_kwargs={}, response_metadata={})]}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use the model with the formatted prompt\n",
        "\n",
        "response = model.invoke(prompt)\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5DpIXsuzMsxX",
        "outputId": "47c442ce-0408-4688-b2f3-7ff143485097"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'नमस्ते (Namaste)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}